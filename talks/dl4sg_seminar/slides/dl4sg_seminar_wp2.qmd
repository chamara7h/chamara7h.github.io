---
format: 
  revealjs:
    slide-number: c/t
    width: 1920
    height: 1080
    logo: "images/logo.png"
    footer: "[WHAT WAS LOST: tracing unmet demand in contraceptive supply chains](https://chamara7h.github.io/talks/)"
    css: theme.css
    theme: simple
    echo: true
    title-slide-logo: "images/logo.png"
editor: source
execute:
  warning: false
  echo: false
---   

<div style="position: relative; width: 100%; height: 100%;">
  <!-- Cardiff logo top-left -->
  <img
    src="images/cardiff_logo.png"
    alt="Cardiff University"
    style="
      position: absolute;
      top: 40px;
      left: 0px;
      width: 110px;
      height: auto;
    "
  />

  <!-- Data Lab logo a bit to the right -->
  <img
    src="images/logo_white.png"
    alt="Data Lab for Social Good"
    style="
      position: absolute;
      top: 40px;
      left: 150px;
      width: 225px;
      height: auto;
    "
  />
  
  <img
    src="images/ukri.png"
    alt="ukri"
    style="
      position: absolute;
      top: 40px;
      left: 415px;
      width: 350px;
      height: auto;
    "
  />
  
  <img
    src="images/wgss.png"
    alt="wgsss"
    style="
      position: absolute;
      top: 40px;
      left: 805px;
      width: 75px;
      height: auto;
    "
  />
  
  <img
    src="images/usaid.png"
    alt="usaid"
    style="
      position: absolute;
      top: 40px;
      left: 930px;
      width: 110px;
      height: auto;
    "
  />
  
  
<br>
<br>
<br>
<br>
<br>


# WHAT WAS LOST {background-image="images/cover.png" background-size="cover" background-color="#4f6952"}

<h2>
Tracing unmet demand in contraceptive supply chains
<h2>

<br>

<h4>
  Harsha Halgamuwe Hewage <br>
  Data Lab for Social Good Research Lab, Cardiff University, UK 
</h4>

<h5>
Supervison team <br>
Prof. Bahman Rostami-Tabar, Prof. Aris Syntetos, Dr. Federico Liberatore
<h5>

<br>

2025-05-20

::: aside
Image generated using ChatGPT.
:::

</div>

```{r}
#| echo: false

library(knitr)
options(knitr.graphics.auto_pdf = TRUE)
```

```{r}
#| label: setup
#| context: setup
#| include: false

# 1. list your CRAN packages
required_packages <- c(
  "tidyverse",
  "knitr",
  "kableExtra",
  "ggthemes",
  "patchwork",
  "tsibble",
  "feasts",
  "viridis",
  "showtext",
  "ggdist",
  'tsutils'
)

# 2. install any that are missing
new_packages <- required_packages[!required_packages %in% installed.packages()[, "Package"]]
if (length(new_packages)) {
  install.packages(new_packages)
}

# 3. load them
invisible(lapply(required_packages, library, character.only = TRUE))

# 4. register and activate the Assistant font
font_add_google("Assistant", "C:/Windows/Fonts/Assistant-Regular.ttf")
showtext_auto()
```

## Outline

<br>

- What was never `counted...`

- The fundamental question

- What we are going to do

- Numerical experiment

- What's `NEXT`

# What was never counted... {background-image="images/story.png" background-size="cover" background-color="#4f6952"}

<br>
<br>

::: aside
Image generated using ChatGPT.
::: 

## Seen the `UNSEEN`

<br>

:::: {.columns style="display: flex; align-items: center;"}

::: {.column-left style="flex: 0 0 50%; display: flex; justify-content: left;"}
<img src="images/story_1.png"
     alt="Story panel"
     style="max-width: 100%; height: auto; display: block;" />
:::

::: {.column style="flex: 0 0 50%; display: flex; flex-direction: column; justify-content: left; text-align: left;"}
This is `Nilu`.

She went to the pharmacy today to get contraceptive `Product A`.

But it wasn't [in stock.]{.highlight-blue-big}
:::

::::

::: aside
Image generated using ChatGPT.
:::

## Seen the `UNSEEN`

<br>

:::: {.columns style="display: flex; align-items: center;"}

::: {.column-left style="flex: 0 0 50%; display: flex; justify-content: left;"}
<img src="images/story_2.png"
     alt="Story panel"
     style="max-width: 100%; height: auto; display: block;" />
:::

::: {.column style="flex: 0 0 50%; display: flex; flex-direction: column; justify-content: left; text-align: left;"}
She didn’t go to the pharmacy today.

[Why would she?]{.highlight-blue-big}

The last two times she went, they didn’t have the product she needed.

The system doesn’t know this.

It sees `“no demand”` and it continously logs Nilu’s silence as data.
:::

::::

::: aside
Image generated using ChatGPT.
:::

## Seen the `UNSEEN`

<br>

:::: {.columns style="display: flex; align-items: center;"}

::: {.column-left style="flex: 0 0 50%; display: flex; justify-content: left;"}
<img src="images/story_3.png"
     alt="Story panel"
     style="max-width: 100%; height: auto; display: block;" />
:::

::: {.column style="flex: 0 0 50%; display: flex; flex-direction: column; justify-content: left; text-align: left;"}
When data is censored by stockouts or service interruptions...

[...forecasts fail.]{.highlight-blue-big}

Not just by being wrong, `But by being blind.`

This creates a broken trust and leads to 

[UNMET DEMAND.]{.highlight-blue-big}
:::

::::

::: aside
Image generated using ChatGPT.
:::

## Seen the `UNSEEN`

<br>

:::: {.columns style="display: flex; align-items: center;"}

::: {.column-left style="flex: 0 0 50%; display: flex; justify-content: left;"}
<img src="images/story_4.png"
     alt="Story panel"
     style="max-width: 100%; height: auto; display: block;" />
:::

::: {.column style="flex: 0 0 50%; display: flex; flex-direction: column; justify-content: left; text-align: left;"}
In reality...

There are more than 

[218 million women]{.highlight-blue-big}

like  Nilu still have an unmet need for family planning.

Ultimately, this results in dropouts, unwanted pregnancies, and almost `7 million hospitalizations` each year in developing countries.
:::

::::

::: aside
Image generated using ChatGPT.

Sources: USAID, 2020; PATH, 2019; Mukasa et al., 2017; Gilda et al., 2016 
:::

## Contraceptive products aren't easily `SUBSTITUTED`

<br>

<img src="images/types.png"
     alt="Story panel"
     style="max-width: 80%; height: auto; display: block;" />

::: aside
*Percent of women who will get pregnant within the first year of typical use.
:::

# The fundamental question

## Key definitions

<br>

- `Stockouts`: Periods when demand is higher than available inventory, leading to censored observations of demand.

- `Interruptions`: Periods when no products are issued despite available stock, thus artificially recorded as zero demand.

- `Censored Demand`: Demand occurring during periods when products are unavailable (stockouts or interruptions), thus not fully observable.

- `True Demand`: Actual demand that would have occurred if sufficient stock was available.

## Censorship scenarios

How can a demand forecasting and inventory optimization model that incorporates lost sales estimation and contextual field data enhance contraceptive supply chain performance and reduce stockouts in developing countries?

```{r}
#| echo: false
#| warning: false
#| label: fig-plot
#| fig-width: 14
#| fig-height: 5
#| fig-cap: "Censorship scenarios in family planning supply chains."

synthetic_tsibble <- read_rds('data/tidy_data/synthetic_data.rds')

# pick one series per

selected <- synthetic_tsibble |>
  filter(store == 'S51', product == 'P8')

# grab the full time‐slice for those series

plot_df <- synthetic_tsibble |>
  semi_join(selected, by = c("series_category","series_type","store","product")) |> 
  mutate(series_type     = str_to_sentence(series_type),
         series_category = str_to_sentence(series_category)) |> 
  group_by(series_category, series_type, store, product) |>
  arrange(date) |>
  mutate(period = row_number()) |>
  ungroup()


# build shading rectangles for each contiguous run of censorship

shade_df <- plot_df |>
  as_tibble() |> 
  arrange(series_category, series_type, store, product, period) |>
  group_by(series_category, series_type, store, product) |>
  mutate(
    run_id = cumsum(
      c(TRUE, censorship_type[-1] != censorship_type[-n()])  
    )
  ) |>
  group_by(series_category, series_type, store, product, run_id, censorship_type) |>
  summarize(start = min(period), end = max(period), .groups = "drop") |>
  filter(censorship_type != "none")

# plot

ggplot() +
  geom_rect(
    data = shade_df,
    aes(xmin = start, xmax = end, ymin = -Inf, ymax = Inf, fill = censorship_type), 
    inherit.aes = FALSE, alpha = 0.25) +
  
  geom_rect(data = shade_df |> 
              filter(start == end),
            aes(xmin = start, xmax = end, ymin = -Inf, ymax = Inf, colour = censorship_type),
            inherit.aes = FALSE, fill = NA,
            size = 0.5, alpha = 0.05, show.legend = FALSE) +
  
  geom_line(data = plot_df,
            aes(x = period, y = actual_demand, colour = "Actual", linetype = "Actual"),
            size = 0.5) +
  
  geom_line(data = plot_df,
            aes(x = period, y = observed_demand, colour = "Observed", linetype = "Observed"),
            size = 0.5) +
  
  scale_fill_manual(name = "Censorship type", values = c(censored   = "gray28", disruption = "#0072B2"),
                    labels = c(censored   = "Stockout", disruption = "Interruption")) +
  
  scale_colour_manual(name   = "Demand", values = c(Actual = "black", Observed = "red")) +
  
  scale_linetype_manual(name = "Demand",values = c(Actual = "solid", Observed = "dashed")) +
  
  labs(x = "Period", y = "Demand") +
  theme_few(base_family = "Assistant", base_size = 22) +
  theme(
    strip.text         = element_text(face = "bold"),
    panel.grid.minor   = element_blank(),
    panel.border       = element_rect(colour = "lightgrey", fill = NA),
    panel.spacing      = unit(0.5, "lines")
  )


```

## Why this is `critical`

<br>

:::: {.columns style="display: flex; align-items: center;"}

::: {.column-left style="flex: 0 0 40%; display: flex; justify-content: left;"}
<img src="images/background.png"
     alt="Story panel"
     style="max-width: 100%; height: auto; display: block;" />
:::

::: {.column style="flex: 0 0 60%; display: flex; flex-direction: column; justify-content: left; text-align: left;"}

::: {.fragment fragment-index=0}
- Frequent stockouts are common in family planning supply chains, especially in developing countries, significantly impacting public health outcomes.
:::

::: {.fragment fragment-index=1}
- During my recent field visit to Ethiopia, stockouts were repeatedly identified by demand planners as a major barrier to effective contraceptive supply management.
:::

::: {.fragment fragment-index=2}
- Traditional forecasting methods fail under censorship.
:::

::: {.fragment fragment-index=3}
- Prior research inadequately addresses demand estimation under conditions of frequent stockouts and interruptions, often leading to biased forecasts and suboptimal inventory decisions.
:::

:::

::::

::: aside
Image generated using ChatGPT.

Sources: Bijvank et al., 2011; Karimi et al., 2021; Thanos et as., 2022 ; Trapero, 2024
:::

# What we are going to do

## How we can fill the gaps

<br>

:::: {.columns style="display: flex; align-items: center;"}

::: {.column-left style="flex: 0 0 40%; display: flex; justify-content: left;"}
<img src="images/rqs.png"
     alt="Story panel"
     style="max-width: 100%; height: auto; display: block;" />
:::

::: {.column style="flex: 0 0 60%; display: flex; flex-direction: column; justify-content: left; text-align: left;"}

::: {.fragment fragment-index=0}
- **`RQ1:`** How accurately can a Tobit Kalman Filter with conformal prediction estimate true demand under censorship?
:::

::: {.fragment fragment-index=1}
- **`RQ2:`** How does demand reconstruction improve inventory performance compared to baseline planning methods?
:::

::: {.fragment fragment-index=2}
- **`RQ3:`** How do planners adjust their orders in response to proposed model-generated recommendations?
:::

:::

::::

::: aside
Image generated using ChatGPT.
:::

## Our proposed framework

<br>

<img src="images/plan.png"
     alt="Story panel"
     style="max-width: 100%; height: auto; display: block;" />

::: aside
We are currently at the green-colored stage.
:::

## First stage: estimating true demand under censorship using tobit kalman filtering and conformal prediction

<br>

<img src="images/tkf_cp_framework.png"
     alt="Story panel"
     style="max-width: 80%; height: auto; display: block;" />

# Numerical experiment

## Experiment setup

<br>

<img src="images/num_experiment.png"
     alt="Story panel"
     style="max-width: 100%; height: auto; display: block;" />

## Data exploration

```{r}
#| echo: false
#| cache: false
#| fig-width: 20
#| fig-height: 10
#| fig-cap: "Actual vs. observed demand for one representative series per type × category, with disruptions and censoring shaded."

# grab the full time‐slice for those series

plot_df <- synthetic_tsibble |>
  mutate(series_type     = str_to_sentence(series_type)) |> 
  group_by(series_type, store, product) |>
  arrange(date) |>
  mutate(period = row_number()) |>
  ungroup()

# build shading rectangles for each contiguous run of censorship

shade_df <- plot_df |>
  as_tibble() |> 
  arrange(series_category, series_type, store, product, period) |>
  group_by(series_category, series_type, store, product) |>
  mutate(
    run_id = cumsum(
      c(TRUE, censorship_type[-1] != censorship_type[-n()])  
    )
  ) |>
  group_by(series_type, store, product, run_id, censorship_type) |>
  summarize(start = min(period), end = max(period), .groups = "drop") |>
  filter(censorship_type != "none")

# plot

ggplot() +
  geom_rect(
    data = shade_df,
    aes(xmin = start, xmax = end, ymin = -Inf, ymax = Inf, fill = censorship_type), 
    inherit.aes = FALSE, alpha = 0.25) +
  
  geom_rect(data = shade_df |> 
              filter(start == end),
            aes(xmin = start, xmax = end, ymin = -Inf, ymax = Inf, colour = censorship_type),
            inherit.aes = FALSE, fill = NA,
            size = 0.5, alpha = 0.05, show.legend = FALSE) +
  
  geom_line(data = plot_df,
            aes(x = period, y = actual_demand, colour = "Actual", linetype = "Actual"),
            size = 0.5) +
  
  geom_line(data = plot_df,
            aes(x = period, y = observed_demand, colour = "Observed", linetype = "Observed"),
            size = 0.5) +
  
  facet_wrap(~series_type, scales = "free_y", ncol = 1) +
  
  scale_fill_manual(name = "Censorship type", values = c(censored   = "gray28", disruption = "#0072B2"),
                    labels = c(censored   = "Censored", disruption = "Disruption")) +
  
  scale_colour_manual(name   = "Demand", values = c(Actual = "black", Observed = "red")) +
  
  scale_linetype_manual(name = "Demand",values = c(Actual = "solid", Observed = "dashed")) +
  
  labs(x = "Period", y = "Demand") +
  theme_few(base_family = "Assistant", base_size = 36) +
  theme(
    strip.text         = element_text(face = "bold"),
    panel.grid.minor   = element_blank(),
    panel.border       = element_rect(colour = "lightgrey", fill = NA),
    panel.spacing      = unit(0.5, "lines")
  )

```

# What did we find?

## Actual vs forecasted demand distributions

```{r}
#| label: fig-ts_plot
#| echo: false
#| cache: false
#| fig-width: 20
#| fig-height: 10
#| fig-cap: "Actual vs. forecasted demand distributions for the different forecasting methods."


pred_master <- read.csv('data/predictions/pred_master.csv') |> 
  filter(model != 'tkf_cp' & model != 'snaive') |> 
  pivot_longer(cols = c(actual_demand, observed_demand, prediction), names_to = 'type', values_to = 'demand') |> 
  mutate(model = if_else(type == 'actual_demand', 'actual_demand', model),
         model = if_else(type == 'observed_demand', 'observed_demand', model)) |> 
  select(-type, -censorship_type) |> 
  distinct() |> 
  mutate(series_type = factor(series_type,
                       levels = c("lumpy","erratic","smooth"),
                       labels = str_to_sentence(c("lumpy","erratic","smooth"))),
    model = case_when(model == 'lr' ~ 'Linear Regression',
                      model == 'moving_average' ~ 'Moving Average',
                      model == 'naive' ~ 'Naive',
                      model == 'tkf_cp_cv' ~ 'TKF CP',
                      model == 'actual_demand' ~ 'Actual Demand',
                      model == 'observed_demand' ~ 'Observed Demand'),
    model = factor(model, levels = c('Actual Demand', 'Observed Demand', "TKF CP", "Naive", "Moving Average", "Linear Regression")),
  )



# Plot densities

pred_master |> 
  ggplot(aes(x = demand, colour = model, linetype = model)) +
  geom_density(size = 1, alpha = 0.8) +
  facet_grid(~series_type, scales = "free") +
  scale_colour_manual(
    name = "Demand / Prediction",
    values = c(
      'Actual Demand'     = "black",
      'Observed Demand'   = "#332288",
      'Linear Regression' = "#009E73",
      'Moving Average'    = "#E69F00",
      'Naive'             = "#D55E00",
      'TKF CP'            = "#0072B2"
    )
  ) +
  scale_linetype_manual(
    name = "Demand / Prediction",
    values = c(
      'Actual Demand'     = "dashed",
      'Observed Demand'   = "solid",
      'Linear Regression' = "solid",
      'Moving Average'    = "solid",
      'Naive'             = "solid",
      'TKF CP'            = "solid"
    )
  ) +
  labs(
    x = "Demand / Prediction",
    y = "Density"
  ) +
  theme_few(base_family = "Assistant", base_size = 36) +
  theme(
    strip.text = element_text(face = "bold"),
    panel.grid.minor = element_blank(),
    panel.border = element_rect(colour = "lightgrey", fill = NA),
    panel.spacing = unit(0.5, "lines")
  ) +
  coord_cartesian(xlim = c(0, 1000))



```

## Overall forecasting and inventory performance across models

<br>

```{r}
#| echo: false
#| results: asis

point_acc <- read_rds('data/results/num_ex_point_acc.rds')
prob_acc  <- read_rds('data/results/num_ex_prob_acc.rds')
inv_meas  <- read_rds('data/results/numerical_experiment_sim.rds')

num_ex_metrics <- point_acc |>
  left_join(prob_acc, by = c('series_category','series_type','store','product','model')) |>
  left_join(inv_meas,  by = c('series_category','series_type','store','product','model'))

# 1) Build & round your summary table
df <- num_ex_metrics |>
  filter(!model %in% c("tkf_cp","snaive")) |>
  group_by(model) |>
  summarise(
    across(where(is.numeric), ~ mean(.x, na.rm = TRUE), .names = "{.col}_mean"),
    .groups = "drop"
  ) |>
  mutate(model = case_when(
    model == "lr"             ~ "Linear Regression",
    model == "moving_average" ~ "Moving Average",
    model == "naive"          ~ "Naive",
    model == "tkf_cp_cv"      ~ "TKF CP"
  )) |>
  arrange(mase_mean) |>
  select(
    model,
    mase_mean,
    avg_pinball_loss_mean,
    CSL_mean,
    lost_sales_rate_mean,
    avg_inventory_investment_mean
  ) |>
  mutate(across(ends_with("_mean"), ~ round(.x, 2))) |>
  mutate(across(everything(), as.character)) |>
  add_row(
    model                         = "",
    mase_mean                     = "",
    avg_pinball_loss_mean         = "",
    CSL_mean                      = "",
    lost_sales_rate_mean          = "",
    avg_inventory_investment_mean = ""
  ) |>
  rename(
    Method                        = model,
    `MASE (mean)`                 = mase_mean,
    `Pin Ball Loss - q95 (mean)`  = avg_pinball_loss_mean,
    `CSL (mean)`                  = CSL_mean,
    `Lost Sales Rate (mean)`      = lost_sales_rate_mean,
    `Inventory coverage (mean)`   = avg_inventory_investment_mean
  )

# 2) Compute the “best” thresholds (ignore blank row)
mase_best <- min(as.numeric(df$`MASE (mean)`),                    na.rm = TRUE)
pbl_best  <- min(as.numeric(df$`Pin Ball Loss - q95 (mean)`),    na.rm = TRUE)
csl_best  <- max(as.numeric(df$`CSL (mean)`),                    na.rm = TRUE)
lsr_best  <- min(as.numeric(df$`Lost Sales Rate (mean)`),        na.rm = TRUE)
icov_best <- max(as.numeric(df$`Inventory coverage (mean)`),     na.rm = TRUE)

# 3) Bold & colour **only** the best cell in each column
df_fmt <- df |>
  mutate(
    `MASE (mean)` = cell_spec(
      `MASE (mean)`,
      bold   = as.numeric(`MASE (mean)`) == mase_best,
      color  = if_else(
        as.numeric(`MASE (mean)`) == mase_best,
        "#4D59AC",    # best → brand blue
        "black",      # others → black
        missing = "black"
      ),
      escape = FALSE
    ),
    `Pin Ball Loss - q95 (mean)` = cell_spec(
      `Pin Ball Loss - q95 (mean)`,
      bold   = as.numeric(`Pin Ball Loss - q95 (mean)`) == pbl_best,
      color  = if_else(
        as.numeric(`Pin Ball Loss - q95 (mean)`) == pbl_best,
        "#4D59AC",
        "black",
        missing = "black"
      ),
      escape = FALSE
    ),
    `CSL (mean)` = cell_spec(
      `CSL (mean)`,
      bold   = as.numeric(`CSL (mean)`) == csl_best,
      color  = if_else(
        as.numeric(`CSL (mean)`) == csl_best,
        "#4D59AC",
        "black",
        missing = "black"
      ),
      escape = FALSE
    ),
    `Lost Sales Rate (mean)` = cell_spec(
      `Lost Sales Rate (mean)`,
      bold   = as.numeric(`Lost Sales Rate (mean)`) == lsr_best,
      color  = if_else(
        as.numeric(`Lost Sales Rate (mean)`) == lsr_best,
        "#4D59AC",
        "black",
        missing = "black"
      ),
      escape = FALSE
    ),
    `Inventory coverage (mean)` = cell_spec(
      `Inventory coverage (mean)`,
      bold   = as.numeric(`Inventory coverage (mean)`) == icov_best,
      color  = if_else(
        as.numeric(`Inventory coverage (mean)`) == icov_best,
        "#DC5555",
        "black",
        missing = "black"
      ),
      escape = FALSE
    )
  )

# 4) Emit the HTML table with your custom class
df_fmt |>
  kbl(
    format     = "html",
    escape     = FALSE,
    table.attr = 'class="table-custom"',
    align      = "lrrrrr"
  ) |>
  kable_styling(full_width = FALSE, font_size = 40)

```

## Performance evaluation - Nemenyi test

```{r}
#| label: fig-metrics_sig
#| echo: false
#| cache: false
#| message: false
#| fig-width: 22.5
#| fig-height: 10
#| fig-cap: "Average ranks of forecasting methods with 95% confidence intervals based on the Nemenyi test for all metrics. Lower ranks indicate better performance."

recode_models <- function(df) {
  df |>
    mutate(model = case_when(
      model == "lr"             ~ "Linear Regression",
      model == "moving_average" ~ "Moving Average",
      model == "naive"          ~ "Naive",
      model == "tkf_cp_cv"      ~ "TKF CP"
    ))
}

# 1) Prepare each metric’s tidy data for Nemenyi
df_tidy_mase <- num_ex_metrics |>
  filter(!model %in% c("tkf_cp","snaive")) |>
  recode_models() |>
  select(-c(rmse, series_category, series_type, crps, CSL,
            lost_sales_rate, avg_inventory_investment, avg_pinball_loss)) |>
  pivot_wider(
    id_cols     = c(store, product),
    names_from  = model,
    values_from = mase
  ) |>
  select(-c(store, product))

df_tidy_pbl <- num_ex_metrics |>
  filter(!model %in% c("tkf_cp","snaive")) |>
  recode_models() |>
  select(-c(rmse, series_category, series_type, crps, CSL,
            lost_sales_rate, avg_inventory_investment, mase)) |>
  pivot_wider(
    id_cols     = c(store, product),
    names_from  = model,
    values_from = avg_pinball_loss
  ) |>
  select(-c(store, product))

df_tidy_csl <- num_ex_metrics |>
  filter(!model %in% c("tkf_cp","snaive")) |>
  recode_models() |>
  mutate(CSL_inv = 1 - CSL) |>
  select(-c(rmse, series_category, series_type, crps, mase,
            lost_sales_rate, avg_inventory_investment, avg_pinball_loss, CSL)) |>
  pivot_wider(
    id_cols     = c(store, product),
    names_from  = model,
    values_from = CSL_inv
  ) |>
  select(-c(store, product))

df_tidy_lsr <- num_ex_metrics |>
  filter(!model %in% c("tkf_cp","snaive")) |>
  recode_models() |>
  select(-c(rmse, series_category, series_type, crps, CSL,
            mase, avg_inventory_investment, avg_pinball_loss)) |>
  pivot_wider(
    id_cols     = c(store, product),
    names_from  = model,
    values_from = lost_sales_rate
  ) |>
  select(-c(store, product))

df_tidy_inv <- num_ex_metrics |>
  filter(!model %in% c("tkf_cp","snaive")) |>
  recode_models() |>
  select(-c(rmse, series_category, series_type, crps, CSL,
            mase, avg_pinball_loss, lost_sales_rate)) |>
  pivot_wider(
    id_cols     = c(store, product),
    names_from  = model,
    values_from = avg_inventory_investment
  ) |>
  select(-c(store, product))

# 1) Define a 2×3 layout: 1 and 2 in row 1, a blank in (1,3); 
#    then 3,4,5 in row 2.

lm <- matrix(c(
  1, 2, 0,
  3, 4, 5
), nrow = 2, byrow = TRUE)

# 2) Tell R to use that layout, with equal widths/heights
layout(lm, widths = c(1,1,1), heights = c(1,1))

# 3) Plot margins & font
par(mar = c(3, 3, 2, 1), oma = c(0, 0, 0, 0), family = "Assistant", cex = 1.5)


# Top‐right: blank
# plot.new()

p1 <- nemenyi(df_tidy_mase,
       conf.level = 0.95,
       plottype   = "vmcb",
       main       = "MASE",
       line = 0.5)

p2 <- nemenyi(df_tidy_pbl,
       conf.level = 0.95,
       plottype   = "vmcb",
       main       = "Pin Ball Loss (q95)",
       line = 0.5)

# Bottom‐left: Achieved CSL (inverted for higher=better)
p3 <- nemenyi(df_tidy_csl,
       conf.level = 0.95,
       plottype   = "vmcb",
       main       = "Achieved CSL",
       line = 0.5)

# Bottom‐middle: Lost Sales Rate
p4 <- nemenyi(df_tidy_lsr,
       conf.level = 0.95,
       plottype   = "vmcb",
       main       = "Lost Sales Rate",
       line = 0.5)

# Bottom‐right: Inventory Coverage
p5 <- nemenyi(df_tidy_inv,
       conf.level = 0.95,
       plottype   = "vmcb",
       main       = "Inventory Coverage",
       line = 0.5)

```

## Performance evaluation - forecasting

```{r}
#| label: fig-fc_metrics_plot
#| echo: false
#| cache: false
#| fig-width: 20
#| fig-height: 10
#| fig-cap: "Forecasting metrics for each series type for the different forecasting methods."

# 1) Prepare long‐format data
plot_df <- num_ex_metrics |>
  filter(!model %in% c("tkf_cp", "snaive")) |>
  mutate(
    model = case_when(
      model == "lr"             ~ "Linear Regression",
      model == "moving_average" ~ "Moving Average",
      model == "naive"          ~ "Naive",
      model == "tkf_cp_cv"      ~ "TKF CP"
    ),
    model = factor(model, levels = c("TKF CP", "Naive", "Moving Average", "Linear Regression")),
    series_type = factor(
      series_type,
      levels = c("lumpy", "erratic", "smooth"),
      labels = str_to_sentence(c("lumpy", "erratic", "smooth"))
    )
  ) |>
  pivot_longer(
    cols = c(mase, avg_pinball_loss, CSL, lost_sales_rate, avg_inventory_investment),
    names_to  = "measure",
    values_to = "value"
  ) |>
  mutate(
    measure = factor(
      measure,
      levels = c("mase", "avg_pinball_loss", "CSL", "lost_sales_rate", "avg_inventory_investment"),
      labels = c(
        "MASE",
        "Pinball Loss (q95)",
        "Achieved CSL",
        "Lost Sales Rate",
        "Inventory Coverage"
      )
    )
  )

# 2) Compute means
mean_df <- plot_df |>
  group_by(series_type, model, measure) |>
  summarise(mean_val = mean(value, na.rm = TRUE), .groups = "drop")

# 3) Define palette
pal <- c(
  'Linear Regression' = "black",
  'Moving Average'              = "#E69F00",
  'Naive'             = "#D55E00",
  'TKF CP'            = "#0072B2"
)

# Plot: Average MASE & Pinball Loss side by side 

p1 <- plot_df |>
  filter(measure == "MASE") |>
  ggplot(aes(x = series_type, y = value, colour = model, fill = model, group = model)) +
  ggdist::stat_halfeye(
    position = "identity",
    width    = 0.6,
    alpha    = 0.4,
    .width   = 0,
    point_interval = NULL
  ) +
  geom_line(
    data     = mean_df |> filter(measure == 'MASE'),
    aes(y    = mean_val),
    size     = 0.8,
    position = "identity"
  ) +
  geom_point(
    data     = mean_df |> filter(measure == 'MASE'),
    aes(y    = mean_val),
    size     = 3,
    shape    = 21,
    fill     = "white",
    stroke   = 1,
    position = "identity"
  ) +
  scale_colour_manual(name = "Model", values = pal) +
  scale_fill_manual(name = "Model", values = pal) +
  labs(x = "Series type", y = NULL, title = 'MASE') +
  theme_few(base_family = "Assistant", base_size = 36) +
  theme(
    legend.position = 'bottom',
    strip.text = element_text(face = "bold"),
    panel.grid.minor = element_blank(),
    panel.border = element_rect(colour = "lightgrey", fill = NA),
    panel.spacing = unit(0.5, "lines")
  ) +
  coord_cartesian(ylim = c(0, 3))

p2 <- plot_df |>
  filter(measure == "Pinball Loss (q95)") |>
  ggplot(aes(x = series_type, y = value, colour = model, fill = model, group = model)) +
  ggdist::stat_halfeye(
    position = "identity",
    width    = 0.6,
    alpha    = 0.4,
    .width   = 0,
    point_interval = NULL
  ) +
  geom_line(
    data     = mean_df |> filter(measure %in% c("Pinball Loss (q95)")),
    aes(y    = mean_val),
    size     = 0.8,
    position = "identity"
  ) +
  geom_point(
    data     = mean_df |> filter(measure %in% c("Pinball Loss (q95)")),
    aes(y    = mean_val),
    size     = 3,
    shape    = 21,
    fill     = "white",
    stroke   = 1,
    position = "identity"
  ) +
  scale_colour_manual(name = "Model", values = pal) +
  scale_fill_manual(name = "Model", values = pal) +
  labs(x = "Series type", y = NULL, title = 'Pinball Loss (q95)') +
  theme_few(base_family = "Assistant", base_size = 36) +
  theme(
    legend.position = 'bottom',
    strip.text = element_text(face = "bold"),
    panel.grid.minor = element_blank(),
    panel.border = element_rect(colour = "lightgrey", fill = NA),
    panel.spacing = unit(0.5, "lines")
  ) 

(p1 | p2) +
  plot_layout(ncol = 2, guides = "collect") &
  theme(legend.position = "bottom")

```

## Performance evaluation - inventory

```{r}
#| label: fig-inv_metrics_plot
#| echo: false
#| cache: false
#| message: false
#| fig-width: 20
#| fig-height: 10
#| fig-cap: "Inentory metrics for each series type for the different forecasting methods."

# Plot: Achieved CSL, Lost Sales Rate  & Inventory Coverage

p1 <- plot_df |>
  filter(measure == "Achieved CSL") |>
  ggplot(aes(x = series_type, y = value, colour = model, fill = model, group = model)) +
  ggdist::stat_halfeye(
    position = "identity",
    width    = 0.6,
    alpha    = 0.4,
    .width   = 0,
    point_interval = NULL
  ) +
  geom_line(
    data     = mean_df |> filter(measure == 'Achieved CSL'),
    aes(y    = mean_val),
    size     = 0.8,
    position = "identity"
  ) +
  geom_point(
    data     = mean_df |> filter(measure == 'Achieved CSL'),
    aes(y    = mean_val),
    size     = 3,
    shape    = 21,
    fill     = "white",
    stroke   = 1,
    position = "identity"
  ) +
  scale_colour_manual(name = "Model", values = pal, guide  = "none") +
  scale_fill_manual(name = "Model", values = pal) +
  labs(x = "Series type", y = NULL, title = 'Achieved CSL') +
  theme_few(base_family = "Assistant", base_size = 36) +
  theme(
    strip.text = element_text(face = "bold"),
    panel.grid.minor = element_blank(),
    panel.border = element_rect(colour = "lightgrey", fill = NA),
    panel.spacing = unit(0.5, "lines")
  ) 

p2 <- plot_df |>
  filter(measure == "Lost Sales Rate") |>
  ggplot(aes(x = series_type, y = value, colour = model, fill = model, group = model)) +
  ggdist::stat_halfeye(
    position = "identity",
    width    = 0.6,
    alpha    = 0.4,
    .width   = 0,
    point_interval = NULL
  ) +
  geom_line(
    data     = mean_df |> filter(measure == 'Lost Sales Rate'),
    aes(y    = mean_val),
    size     = 0.8,
    position = "identity"
  ) +
  geom_point(
    data     = mean_df |> filter(measure == 'Lost Sales Rate'),
    aes(y    = mean_val),
    size     = 3,
    shape    = 21,
    fill     = "white",
    stroke   = 1,
    position = "identity"
  ) +
  scale_colour_manual(name = "Model", values = pal, guide  = "none") +
  scale_fill_manual(name = "Model", values = pal) +
  labs(x = "Series type", y = NULL, title = 'Lost Sales Rate') +
  theme_few(base_family = "Assistant", base_size = 36) +
  theme(
    strip.text = element_text(face = "bold"),
    panel.grid.minor = element_blank(),
    panel.border = element_rect(colour = "lightgrey", fill = NA),
    panel.spacing = unit(0.5, "lines")
  )

p3 <- plot_df |>
  filter(measure == "Inventory Coverage" & value < 300) |>
  ggplot(aes(x = series_type, y = value, colour = model, fill = model, group = model)) +
  ggdist::stat_halfeye(
    position = "identity",
    width    = 0.6,
    alpha    = 0.4,
    .width   = 0,
    point_interval = NULL
  ) +
  geom_line(
    data     = mean_df |> filter(measure == 'Inventory Coverage' & !model %in% c('Naive', 'Moving Average')),
    aes(y    = mean_val),
    size     = 0.8,
    position = "identity"
  ) +
  geom_point(
    data     = mean_df |> filter(measure == 'Inventory Coverage'),
    aes(y    = mean_val),
    size     = 3,
    shape    = 21,
    fill     = "white",
    stroke   = 1,
    position = "identity"
  ) +
  scale_colour_manual(name = "Model", values = pal, guide  = "none") +
  scale_fill_manual(name = "Model", values = pal) +
  labs(x = "Series type", y = NULL, title = 'Inventory Coverage') +
  theme_few(base_family = "Assistant", base_size = 36) +
  theme(
    strip.text = element_text(face = "bold"),
    panel.grid.minor = element_blank(),
    panel.border = element_rect(colour = "lightgrey", fill = NA),
    panel.spacing = unit(0.5, "lines")
  ) +
  coord_cartesian(ylim = c(0, 10))

(p1 | p2 |p3) +
  plot_layout(ncol = 3, guides = "collect") &
  theme(legend.position = "bottom")

```

# What's `NEXT`

## Way forward

:::: {.columns style="display: flex; align-items: center;"}

::: {.column-left style="flex: 0 0 50%; display: flex; justify-content: left;"}
<img src="images/story_5.png"
     alt="Story panel"
     style="max-width: 90%; height: auto; display: block;" />
:::

::: {.column style="flex: 0 0 50%; display: flex; flex-direction: column; justify-content: left; text-align: left;"}
Develop a  more comprehensive inventory policy using forecasted quantiles
→ `Incorporate uncertainty directly into order decisions`

<br>

Extend empirical model with external covariates
→ `Account for special events, disruptions, and policy shifts`

<br>

Conduct lab experiment with real demand planners
→ `Measure how model recommendations affect decision-making`

:::

::::

::: aside
Image generated using ChatGPT.
:::

## Materials

<br>

<img src="images/git.png"
     style="max-width: 10%; height: auto; display: block;" />

You can find the slides [here](https://chamara7h.github.io/talks/).

# Any questions or thoughts? 💬

##

![](images/follow_us.png){fig-align="center"}